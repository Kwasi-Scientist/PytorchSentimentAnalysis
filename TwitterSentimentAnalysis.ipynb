{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision\n",
    "from collections import Counter\n",
    "import spacy\n",
    "import tqdm as tqdm\n",
    "import string\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "\n",
    "import ignite\n",
    "from ignite.engine import Engine, Events\n",
    "from ignite.metrics import Accuracy, Loss, RunningAverage\n",
    "from ignite.handlers import ModelCheckpoint, EarlyStopping\n",
    "from ignite.contrib.handlers import ProgressBar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://medium.com/@sonicboom8/sentiment-analysis-with-variable-length-sequences-in-pytorch-6241635ae130"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data\n",
    "dataset = pd.read_csv(r'./SentimentAnalysisDataset.csv', error_bad_lines=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot data \n",
    "figure = plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x = dataset.Sentiment.unique(), y = dataset.Sentiment.value_counts())\n",
    "ax.set(xlabel='label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL frie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trail...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!   ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment SentimentSource  \\\n",
       "0       1          0    Sentiment140   \n",
       "1       2          0    Sentiment140   \n",
       "2       3          1    Sentiment140   \n",
       "3       4          0    Sentiment140   \n",
       "4       5          0    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \n",
       "0                       is so sad for my APL frie...  \n",
       "1                     I missed the New Moon trail...  \n",
       "2                            omg its already 7:30 :O  \n",
       "3            .. Omgaga. Im sooo  im gunna CRy. I'...  \n",
       "4           i think mi bf is cheating on me!!!   ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1578612, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove trailing and leading spaces\n",
    "dataset['SentmentText'] = dataset['SentimentText'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Spacy Tokenizer\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 1578612/1578612 [10:52<00:00, 2418.01it/s]\n"
     ]
    }
   ],
   "source": [
    "#There is an even split \n",
    "#Now create bag of words with all the data in the tweets \n",
    "#this is also called tokenizing the data \n",
    "#We create an index mapping dict where the most common words have low indexes\n",
    "#can use Counter from Collections\n",
    "\n",
    "\n",
    "words = Counter()\n",
    "punct = '!#$%&()\\'\\'\\\"\\\"*+,-./:;<=>?@[\\]^_`{|}~'\n",
    "for i in tqdm.tqdm(dataset['SentimentText'].values):\n",
    "    i = i.strip()\n",
    "    #i= i.strip(punct)\n",
    "    i.translate(str.maketrans('','',string.punctuation))\n",
    "    i = nlp(i)\n",
    "    words.update(i)\n",
    "    #words.update(i.lower() for i in nlp(i))\n",
    "    #words.update(x.lower() for x in nlp(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sort so most frequent woccur first\n",
    "words = sorted(words, key = words.get, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add <pad> and <unk> token to vocab which will be used later\n",
    "words = ['_PAD','_UNK'] + words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_PAD',\n",
       " '_UNK',\n",
       " is,\n",
       " so,\n",
       " sad,\n",
       " for,\n",
       " my,\n",
       " APL,\n",
       " friend,\n",
       " .............,\n",
       " I,\n",
       " missed,\n",
       " the,\n",
       " New,\n",
       " Moon,\n",
       " trailer,\n",
       " ...,\n",
       " omg,\n",
       " its,\n",
       " already,\n",
       " 7:30,\n",
       " :O,\n",
       " ..,\n",
       " Omgaga,\n",
       " .,\n",
       " I,\n",
       " m,\n",
       " sooo,\n",
       "  ,\n",
       " i,\n",
       " m,\n",
       " gunna,\n",
       " CRy,\n",
       " .,\n",
       " I,\n",
       " 've,\n",
       " been,\n",
       " at,\n",
       " this,\n",
       " dentist,\n",
       " since,\n",
       " 11,\n",
       " ..,\n",
       " I,\n",
       " was,\n",
       " suposed,\n",
       " 2,\n",
       " just,\n",
       " get,\n",
       " a,\n",
       " crown,\n",
       " put,\n",
       " on,\n",
       " (,\n",
       " 30mins,\n",
       " ),\n",
       " ...,\n",
       " i,\n",
       " think,\n",
       " mi,\n",
       " bf,\n",
       " is,\n",
       " cheating,\n",
       " on,\n",
       " me,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       "       ,\n",
       " T_T,\n",
       " or,\n",
       " i,\n",
       " just,\n",
       " worry,\n",
       " too,\n",
       " much,\n",
       " ?,\n",
       " Juuuuuuuuuuuuuuuuussssst,\n",
       " Chillin,\n",
       " !,\n",
       " !,\n",
       " Sunny,\n",
       " Again,\n",
       "        ,\n",
       " Work,\n",
       " Tomorrow,\n",
       "  ,\n",
       " :-|,\n",
       "       ,\n",
       " TV,\n",
       " Tonight,\n",
       " handed,\n",
       " in,\n",
       " my,\n",
       " uniform,\n",
       " today,\n",
       " .,\n",
       " i,\n",
       " miss,\n",
       " you,\n",
       " already,\n",
       " hmmmm,\n",
       " ....,\n",
       " i,\n",
       " wonder,\n",
       " how,\n",
       " she,\n",
       " my,\n",
       " number,\n",
       " @-,\n",
       " ),\n",
       " I,\n",
       " must,\n",
       " think,\n",
       " about,\n",
       " positive,\n",
       " ..,\n",
       " thanks,\n",
       " to,\n",
       " all,\n",
       " the,\n",
       " haters,\n",
       " up,\n",
       " in,\n",
       " my,\n",
       " face,\n",
       " all,\n",
       " day,\n",
       " !,\n",
       " 112,\n",
       " -,\n",
       " 102,\n",
       " this,\n",
       " weekend,\n",
       " has,\n",
       " sucked,\n",
       " so,\n",
       " far,\n",
       " jb,\n",
       " is,\n",
       " nt,\n",
       " showing,\n",
       " in,\n",
       " australia,\n",
       " any,\n",
       " more,\n",
       " !,\n",
       " ok,\n",
       " that,\n",
       " s,\n",
       " it,\n",
       " you,\n",
       " win,\n",
       " .,\n",
       " &,\n",
       " lt;--------,\n",
       " This,\n",
       " is,\n",
       " the,\n",
       " way,\n",
       " i,\n",
       " feel,\n",
       " right,\n",
       " now,\n",
       " ...,\n",
       " awhhe,\n",
       " man,\n",
       " ....,\n",
       " I,\n",
       " 'm,\n",
       " completely,\n",
       " useless,\n",
       " rt,\n",
       " now,\n",
       " .,\n",
       " Funny,\n",
       " ,,\n",
       " all,\n",
       " I,\n",
       " can,\n",
       " do,\n",
       " is,\n",
       " twitter,\n",
       " .,\n",
       " http://myloc.me/27HX,\n",
       " Feeling,\n",
       " strangely,\n",
       " fine,\n",
       " .,\n",
       " Now,\n",
       " I,\n",
       " 'm,\n",
       " gon,\n",
       " na,\n",
       " go,\n",
       " listen,\n",
       " to,\n",
       " some,\n",
       " Semisonic,\n",
       " to,\n",
       " celebrate,\n",
       " HUGE,\n",
       " roll,\n",
       " of,\n",
       " thunder,\n",
       " just,\n",
       " now,\n",
       " ...,\n",
       " SO,\n",
       " scary,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " I,\n",
       " just,\n",
       " cut,\n",
       " my,\n",
       " beard,\n",
       " off,\n",
       " .,\n",
       " It,\n",
       " 's,\n",
       " only,\n",
       " been,\n",
       " growing,\n",
       " for,\n",
       " well,\n",
       " over,\n",
       " a,\n",
       " year,\n",
       " .,\n",
       " I,\n",
       " 'm,\n",
       " gon,\n",
       " na,\n",
       " start,\n",
       " it,\n",
       " over,\n",
       " .,\n",
       " @shaunamanu,\n",
       " is,\n",
       " happy,\n",
       " in,\n",
       " the,\n",
       " meantime,\n",
       " .,\n",
       " Very,\n",
       " sad,\n",
       " about,\n",
       " Iran,\n",
       " .,\n",
       " wompppp,\n",
       " wompp,\n",
       " You,\n",
       " 're,\n",
       " the,\n",
       " only,\n",
       " one,\n",
       " who,\n",
       " can,\n",
       " see,\n",
       " this,\n",
       " cause,\n",
       " no,\n",
       " one,\n",
       " else,\n",
       " is,\n",
       " following,\n",
       " me,\n",
       " this,\n",
       " is,\n",
       " for,\n",
       " you,\n",
       " because,\n",
       " you,\n",
       " 're,\n",
       " pretty,\n",
       " awesome,\n",
       " &,\n",
       " lt;---Sad,\n",
       " level,\n",
       " is,\n",
       " 3,\n",
       " .,\n",
       " I,\n",
       " was,\n",
       " writing,\n",
       " a,\n",
       " massive,\n",
       " blog,\n",
       " tweet,\n",
       " on,\n",
       " Myspace,\n",
       " and,\n",
       " my,\n",
       " comp,\n",
       " shut,\n",
       " down,\n",
       " .,\n",
       " Now,\n",
       " it,\n",
       " 's,\n",
       " all,\n",
       " lost,\n",
       " *,\n",
       " lays,\n",
       " in,\n",
       " fetal,\n",
       " position,\n",
       " *,\n",
       " ...,\n",
       "  ,\n",
       " Headed,\n",
       " to,\n",
       " Hospitol,\n",
       " :,\n",
       " Had,\n",
       " to,\n",
       " pull,\n",
       " out,\n",
       " of,\n",
       " the,\n",
       " Golf,\n",
       " Tourny,\n",
       " in,\n",
       " 3rd,\n",
       " place,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " I,\n",
       " Think,\n",
       " I,\n",
       " Re,\n",
       " -,\n",
       " Ripped,\n",
       " something,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " Yeah,\n",
       " THAT,\n",
       " !,\n",
       " !,\n",
       " BoRinG,\n",
       "   ,\n",
       " ):,\n",
       " what,\n",
       " s,\n",
       " wrong,\n",
       " with,\n",
       " him,\n",
       " ?,\n",
       " ?,\n",
       "     ,\n",
       " Please,\n",
       " tell,\n",
       " me,\n",
       " ........,\n",
       "   ,\n",
       " :-/,\n",
       " ca,\n",
       " n't,\n",
       " be,\n",
       " bothered,\n",
       " .,\n",
       " i,\n",
       " wish,\n",
       " i,\n",
       " could,\n",
       " spend,\n",
       " the,\n",
       " rest,\n",
       " of,\n",
       " my,\n",
       " life,\n",
       " just,\n",
       " sat,\n",
       " here,\n",
       " and,\n",
       " going,\n",
       " to,\n",
       " gigs,\n",
       " .,\n",
       " seriously,\n",
       " .,\n",
       " Feeeling,\n",
       " like,\n",
       " shit,\n",
       " right,\n",
       " now,\n",
       " .,\n",
       " I,\n",
       " really,\n",
       " want,\n",
       " to,\n",
       " sleep,\n",
       " ,,\n",
       " but,\n",
       " nooo,\n",
       " I,\n",
       " have,\n",
       " 3,\n",
       " hours,\n",
       " of,\n",
       " dancing,\n",
       " and,\n",
       " an,\n",
       " art,\n",
       " assignment,\n",
       " to,\n",
       " finish,\n",
       " .,\n",
       " goodbye,\n",
       " exams,\n",
       " ,,\n",
       " HELLO,\n",
       " ALCOHOL,\n",
       " TONIGHT,\n",
       " I,\n",
       " did,\n",
       " n't,\n",
       " realize,\n",
       " it,\n",
       " was,\n",
       " THAT,\n",
       " deep,\n",
       " .,\n",
       " Geez,\n",
       " give,\n",
       " a,\n",
       " girl,\n",
       " a,\n",
       " warning,\n",
       " atleast,\n",
       " !,\n",
       " I,\n",
       " hate,\n",
       " it,\n",
       " when,\n",
       " any,\n",
       " athlete,\n",
       " appears,\n",
       " to,\n",
       " tear,\n",
       " an,\n",
       " ACL,\n",
       " on,\n",
       " live,\n",
       " television,\n",
       " .,\n",
       " i,\n",
       " miss,\n",
       " you,\n",
       " guys,\n",
       " too,\n",
       "     ,\n",
       " i,\n",
       " think,\n",
       " i,\n",
       " 'm,\n",
       " wearing,\n",
       " skinny,\n",
       " jeans,\n",
       " a,\n",
       " cute,\n",
       " sweater,\n",
       " and,\n",
       " heels,\n",
       "   ,\n",
       " not,\n",
       " really,\n",
       " sure,\n",
       "   ,\n",
       " what,\n",
       " are,\n",
       " you,\n",
       " doing,\n",
       " today,\n",
       " --,\n",
       " Meet,\n",
       " your,\n",
       " Meat,\n",
       " http://bit.ly/15SSCI,\n",
       " My,\n",
       " horsie,\n",
       " is,\n",
       " moving,\n",
       " on,\n",
       " Saturday,\n",
       " morning,\n",
       " .,\n",
       " No,\n",
       " Sat,\n",
       " off,\n",
       " ...,\n",
       " Need,\n",
       " to,\n",
       " work,\n",
       " 6,\n",
       " days,\n",
       " a,\n",
       " week,\n",
       " Really,\n",
       " Do,\n",
       " nt,\n",
       " Like,\n",
       " Doing,\n",
       " my,\n",
       " Room,\n",
       " Its,\n",
       " So,\n",
       " Boring,\n",
       "  ,\n",
       " Sick,\n",
       " Of,\n",
       " Doing,\n",
       " My,\n",
       " Wardrobe,\n",
       " Out,\n",
       " Ca,\n",
       " nt,\n",
       " Waiit,\n",
       " Till,\n",
       " I,\n",
       " Have,\n",
       " My,\n",
       " Walk,\n",
       " In,\n",
       " One,\n",
       "  ,\n",
       " Yay,\n",
       " SOX,\n",
       " !,\n",
       "     ,\n",
       " Floyd,\n",
       " was,\n",
       " great,\n",
       " ,,\n",
       " but,\n",
       " relievers,\n",
       " need,\n",
       " a,\n",
       " scolding,\n",
       " !,\n",
       " times,\n",
       " by,\n",
       " like,\n",
       " a,\n",
       " million,\n",
       " uploading,\n",
       " pictures,\n",
       " on,\n",
       " friendster,\n",
       " what,\n",
       " type,\n",
       " of,\n",
       " a,\n",
       " spaz,\n",
       " downloads,\n",
       " a,\n",
       " virus,\n",
       " ?,\n",
       " my,\n",
       " brother,\n",
       " that,\n",
       " 's,\n",
       " who,\n",
       " :,\n",
       " \\,\n",
       " MSN,\n",
       " is,\n",
       " now,\n",
       " fucked,\n",
       " forever,\n",
       "    ,\n",
       " :'(,\n",
       " &,\n",
       " amp;&amp;Fightiin,\n",
       " Wiit,\n",
       " The,\n",
       " Babes,\n",
       " ...,\n",
       " (:,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " !,\n",
       " -,\n",
       " so,\n",
       " i,\n",
       " wrote,\n",
       " something,\n",
       " last,\n",
       " week,\n",
       " .,\n",
       " and,\n",
       " i,\n",
       " got,\n",
       " a,\n",
       " call,\n",
       " from,\n",
       " someone,\n",
       " in,\n",
       " the,\n",
       " new,\n",
       " york,\n",
       " office,\n",
       " ...,\n",
       " http://tumblr.com/xcn21w6o7,\n",
       " *,\n",
       " enough,\n",
       " said,\n",
       " *,\n",
       " ...,\n",
       " Do,\n",
       " I,\n",
       " need,\n",
       " to,\n",
       " even,\n",
       " say,\n",
       " it,\n",
       " ?,\n",
       "  ,\n",
       " Do,\n",
       " I,\n",
       " ?,\n",
       "  ,\n",
       " Well,\n",
       " ,,\n",
       " here,\n",
       " I,\n",
       " go,\n",
       " anyways,\n",
       " :,\n",
       "  ,\n",
       " CHRIS,\n",
       " CORNELL,\n",
       " IN,\n",
       " CHICAGO,\n",
       " !,\n",
       "  ,\n",
       " ...,\n",
       " TONIGHT,\n",
       " !,\n",
       " ...,\n",
       " health,\n",
       " class,\n",
       " (,\n",
       " what,\n",
       " a,\n",
       " joke,\n",
       " !,\n",
       " ),\n",
       " @ginaaa,\n",
       " &,\n",
       " lt;3,\n",
       " GO,\n",
       " TO,\n",
       " THE,\n",
       " SHOW,\n",
       " TONIGHT,\n",
       " @Spiral_galaxy,\n",
       " @YMPtweet,\n",
       "  ,\n",
       " it,\n",
       " really,\n",
       " makes,\n",
       " me,\n",
       " sad,\n",
       " when,\n",
       " i,\n",
       " look,\n",
       " at,\n",
       " Muslims,\n",
       " reality,\n",
       " now,\n",
       " -,\n",
       " All,\n",
       " Time,\n",
       " Low,\n",
       " shall,\n",
       " be,\n",
       " my,\n",
       " motivation,\n",
       " for,\n",
       " the,\n",
       " rest,\n",
       " of,\n",
       " the,\n",
       " week,\n",
       " .,\n",
       " and,\n",
       " the,\n",
       " entertainment,\n",
       " is,\n",
       " over,\n",
       " ,,\n",
       " someone,\n",
       " complained,\n",
       " properly,\n",
       " ..,\n",
       "   ,\n",
       " @rupturerapture,\n",
       " experimental,\n",
       " you,\n",
       " say,\n",
       " ?,\n",
       " he,\n",
       " should,\n",
       " experiment,\n",
       " with,\n",
       " a,\n",
       " melody,\n",
       " another,\n",
       " year,\n",
       " of,\n",
       " Lakers,\n",
       " ..,\n",
       " That,\n",
       " 's,\n",
       " neither,\n",
       " magic,\n",
       " nor,\n",
       " fun,\n",
       " ...,\n",
       " baddest,\n",
       " day,\n",
       " eveer,\n",
       " .,\n",
       " bathroom,\n",
       " is,\n",
       " clean,\n",
       " .....,\n",
       " now,\n",
       " on,\n",
       " to,\n",
       " more,\n",
       " enjoyable,\n",
       " tasks,\n",
       " ......,\n",
       " boom,\n",
       " boom,\n",
       " pow,\n",
       " but,\n",
       " i,\n",
       " 'm,\n",
       " proud,\n",
       " .,\n",
       " congrats,\n",
       " to,\n",
       " helio,\n",
       " though,\n",
       " David,\n",
       " must,\n",
       " be,\n",
       " hospitalized,\n",
       " for,\n",
       " five,\n",
       " days,\n",
       " end,\n",
       " of,\n",
       " July,\n",
       " (,\n",
       " palatine,\n",
       " tonsils,\n",
       " ),\n",
       " .,\n",
       " I,\n",
       " will,\n",
       " probably,\n",
       " never,\n",
       " see,\n",
       " Katie,\n",
       " in,\n",
       " concert,\n",
       " .,\n",
       " friends,\n",
       " are,\n",
       " leaving,\n",
       " me,\n",
       " 'cause,\n",
       " of,\n",
       " this,\n",
       " stupid,\n",
       " love,\n",
       "  ,\n",
       " http://bit.ly/ZoxZC,\n",
       " go,\n",
       " give,\n",
       " ur,\n",
       " mom,\n",
       " a,\n",
       " hug,\n",
       " right,\n",
       " now,\n",
       " .,\n",
       " http://bit.ly/azFwv,\n",
       " Going,\n",
       " To,\n",
       " See,\n",
       " Harry,\n",
       " Sunday,\n",
       " Happiness,\n",
       " Hand,\n",
       " quilting,\n",
       " it,\n",
       " is,\n",
       " then,\n",
       " ...,\n",
       " hate,\n",
       " u,\n",
       " ...,\n",
       "  ,\n",
       " leysh,\n",
       " t9ar5,\n",
       " ...,\n",
       " =,\n",
       " (,\n",
       " (,\n",
       " (,\n",
       " (,\n",
       " (,\n",
       " (,\n",
       " (,\n",
       " ..,\n",
       " -,\n",
       "  ,\n",
       " I,\n",
       " always,\n",
       " get,\n",
       " what,\n",
       " I,\n",
       " want,\n",
       " I,\n",
       " bend,\n",
       " backwards,\n",
       " i,\n",
       " get,\n",
       " off,\n",
       " work,\n",
       " sooooon,\n",
       " !,\n",
       " i,\n",
       " miss,\n",
       " cody,\n",
       " booo,\n",
       " .,\n",
       " have,\n",
       " n't,\n",
       " seen,\n",
       " him,\n",
       " in,\n",
       " foreverr,\n",
       " !,\n",
       " I,\n",
       " hate,\n",
       " allergies,\n",
       " .,\n",
       " Should,\n",
       " I,\n",
       " get,\n",
       " my,\n",
       " hair,\n",
       " cut,\n",
       " tomorrow,\n",
       " ?,\n",
       " I,\n",
       " 'm,\n",
       " taking,\n",
       " a,\n",
       " public,\n",
       " poll,\n",
       " ...,\n",
       " -,\n",
       " I,\n",
       " love,\n",
       " you,\n",
       " guys,\n",
       " so,\n",
       " much,\n",
       " that,\n",
       " it,\n",
       " hurts,\n",
       " .,\n",
       " http://tumblr.com/xkh1z19us,\n",
       " I,\n",
       " miss,\n",
       " Earl,\n",
       " I,\n",
       " miss,\n",
       " New,\n",
       " Jersey,\n",
       " I,\n",
       " missed,\n",
       " the,\n",
       " first,\n",
       " hour,\n",
       " of,\n",
       " SYTYCD,\n",
       " last,\n",
       " night,\n",
       " ,,\n",
       " and,\n",
       " I,\n",
       " ca,\n",
       " n't,\n",
       " find,\n",
       " it,\n",
       " online,\n",
       " !,\n",
       " I,\n",
       " need,\n",
       " a,\n",
       " U2,\n",
       " fix,\n",
       " NOW,\n",
       " !,\n",
       " I,\n",
       " never,\n",
       " thought,\n",
       " I,\n",
       " 'd,\n",
       " become,\n",
       " second,\n",
       " choice,\n",
       " ...,\n",
       " I,\n",
       " think,\n",
       " I,\n",
       " may,\n",
       " be,\n",
       " too,\n",
       " friendly,\n",
       " ...,\n",
       " lol,\n",
       " ...,\n",
       " o,\n",
       " well,\n",
       " ...,\n",
       " I,\n",
       " think,\n",
       " Manuel,\n",
       " (,\n",
       " my,\n",
       " Basil,\n",
       " plant,\n",
       " ),\n",
       " only,\n",
       " has,\n",
       " days,\n",
       " to,\n",
       " live,\n",
       " I,\n",
       " wanna,\n",
       " be,\n",
       " at,\n",
       " home,\n",
       " @,\n",
       " church,\n",
       " ...,\n",
       " I,\n",
       " wonder,\n",
       " wht,\n",
       " they,\n",
       " are,\n",
       " doing,\n",
       " ?,\n",
       " i,\n",
       " wanna,\n",
       " make,\n",
       " my,\n",
       " own,\n",
       " pizza,\n",
       " i,\n",
       " want,\n",
       " a,\n",
       " 120,\n",
       " gb,\n",
       " harddrive,\n",
       " ,,\n",
       " or,\n",
       " a,\n",
       " 37,\n",
       " inch,\n",
       " tv,\n",
       " ,,\n",
       " or,\n",
       " a,\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create word to index dict\n",
    "word2index = {k:v for v,k in enumerate(words)}\n",
    "index2words = {i:o for i, o in enumerate(words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_PAD': 0,\n",
       " '_UNK': 1,\n",
       " is: 2,\n",
       " so: 3,\n",
       " sad: 4,\n",
       " for: 5,\n",
       " my: 6,\n",
       " APL: 7,\n",
       " friend: 8,\n",
       " .............: 9,\n",
       " I: 10,\n",
       " missed: 11,\n",
       " the: 12,\n",
       " New: 13,\n",
       " Moon: 14,\n",
       " trailer: 15,\n",
       " ...: 16,\n",
       " omg: 17,\n",
       " its: 18,\n",
       " already: 19,\n",
       " 7:30: 20,\n",
       " :O: 21,\n",
       " ..: 22,\n",
       " Omgaga: 23,\n",
       " .: 24,\n",
       " I: 25,\n",
       " m: 26,\n",
       " sooo: 27,\n",
       "  : 28,\n",
       " i: 29,\n",
       " m: 30,\n",
       " gunna: 31,\n",
       " CRy: 32,\n",
       " .: 33,\n",
       " I: 34,\n",
       " 've: 35,\n",
       " been: 36,\n",
       " at: 37,\n",
       " this: 38,\n",
       " dentist: 39,\n",
       " since: 40,\n",
       " 11: 41,\n",
       " ..: 42,\n",
       " I: 43,\n",
       " was: 44,\n",
       " suposed: 45,\n",
       " 2: 46,\n",
       " just: 47,\n",
       " get: 48,\n",
       " a: 49,\n",
       " crown: 50,\n",
       " put: 51,\n",
       " on: 52,\n",
       " (: 53,\n",
       " 30mins: 54,\n",
       " ): 55,\n",
       " ...: 56,\n",
       " i: 57,\n",
       " think: 58,\n",
       " mi: 59,\n",
       " bf: 60,\n",
       " is: 61,\n",
       " cheating: 62,\n",
       " on: 63,\n",
       " me: 64,\n",
       " !: 65,\n",
       " !: 66,\n",
       " !: 67,\n",
       "       : 68,\n",
       " T_T: 69,\n",
       " or: 70,\n",
       " i: 71,\n",
       " just: 72,\n",
       " worry: 73,\n",
       " too: 74,\n",
       " much: 75,\n",
       " ?: 76,\n",
       " Juuuuuuuuuuuuuuuuussssst: 77,\n",
       " Chillin: 78,\n",
       " !: 79,\n",
       " !: 80,\n",
       " Sunny: 81,\n",
       " Again: 82,\n",
       "        : 83,\n",
       " Work: 84,\n",
       " Tomorrow: 85,\n",
       "  : 86,\n",
       " :-|: 87,\n",
       "       : 88,\n",
       " TV: 89,\n",
       " Tonight: 90,\n",
       " handed: 91,\n",
       " in: 92,\n",
       " my: 93,\n",
       " uniform: 94,\n",
       " today: 95,\n",
       " .: 96,\n",
       " i: 97,\n",
       " miss: 98,\n",
       " you: 99,\n",
       " already: 100,\n",
       " hmmmm: 101,\n",
       " ....: 102,\n",
       " i: 103,\n",
       " wonder: 104,\n",
       " how: 105,\n",
       " she: 106,\n",
       " my: 107,\n",
       " number: 108,\n",
       " @-: 109,\n",
       " ): 110,\n",
       " I: 111,\n",
       " must: 112,\n",
       " think: 113,\n",
       " about: 114,\n",
       " positive: 115,\n",
       " ..: 116,\n",
       " thanks: 117,\n",
       " to: 118,\n",
       " all: 119,\n",
       " the: 120,\n",
       " haters: 121,\n",
       " up: 122,\n",
       " in: 123,\n",
       " my: 124,\n",
       " face: 125,\n",
       " all: 126,\n",
       " day: 127,\n",
       " !: 128,\n",
       " 112: 129,\n",
       " -: 130,\n",
       " 102: 131,\n",
       " this: 132,\n",
       " weekend: 133,\n",
       " has: 134,\n",
       " sucked: 135,\n",
       " so: 136,\n",
       " far: 137,\n",
       " jb: 138,\n",
       " is: 139,\n",
       " nt: 140,\n",
       " showing: 141,\n",
       " in: 142,\n",
       " australia: 143,\n",
       " any: 144,\n",
       " more: 145,\n",
       " !: 146,\n",
       " ok: 147,\n",
       " that: 148,\n",
       " s: 149,\n",
       " it: 150,\n",
       " you: 151,\n",
       " win: 152,\n",
       " .: 153,\n",
       " &: 154,\n",
       " lt;--------: 155,\n",
       " This: 156,\n",
       " is: 157,\n",
       " the: 158,\n",
       " way: 159,\n",
       " i: 160,\n",
       " feel: 161,\n",
       " right: 162,\n",
       " now: 163,\n",
       " ...: 164,\n",
       " awhhe: 165,\n",
       " man: 166,\n",
       " ....: 167,\n",
       " I: 168,\n",
       " 'm: 169,\n",
       " completely: 170,\n",
       " useless: 171,\n",
       " rt: 172,\n",
       " now: 173,\n",
       " .: 174,\n",
       " Funny: 175,\n",
       " ,: 176,\n",
       " all: 177,\n",
       " I: 178,\n",
       " can: 179,\n",
       " do: 180,\n",
       " is: 181,\n",
       " twitter: 182,\n",
       " .: 183,\n",
       " http://myloc.me/27HX: 184,\n",
       " Feeling: 185,\n",
       " strangely: 186,\n",
       " fine: 187,\n",
       " .: 188,\n",
       " Now: 189,\n",
       " I: 190,\n",
       " 'm: 191,\n",
       " gon: 192,\n",
       " na: 193,\n",
       " go: 194,\n",
       " listen: 195,\n",
       " to: 196,\n",
       " some: 197,\n",
       " Semisonic: 198,\n",
       " to: 199,\n",
       " celebrate: 200,\n",
       " HUGE: 201,\n",
       " roll: 202,\n",
       " of: 203,\n",
       " thunder: 204,\n",
       " just: 205,\n",
       " now: 206,\n",
       " ...: 207,\n",
       " SO: 208,\n",
       " scary: 209,\n",
       " !: 210,\n",
       " !: 211,\n",
       " !: 212,\n",
       " !: 213,\n",
       " I: 214,\n",
       " just: 215,\n",
       " cut: 216,\n",
       " my: 217,\n",
       " beard: 218,\n",
       " off: 219,\n",
       " .: 220,\n",
       " It: 221,\n",
       " 's: 222,\n",
       " only: 223,\n",
       " been: 224,\n",
       " growing: 225,\n",
       " for: 226,\n",
       " well: 227,\n",
       " over: 228,\n",
       " a: 229,\n",
       " year: 230,\n",
       " .: 231,\n",
       " I: 232,\n",
       " 'm: 233,\n",
       " gon: 234,\n",
       " na: 235,\n",
       " start: 236,\n",
       " it: 237,\n",
       " over: 238,\n",
       " .: 239,\n",
       " @shaunamanu: 240,\n",
       " is: 241,\n",
       " happy: 242,\n",
       " in: 243,\n",
       " the: 244,\n",
       " meantime: 245,\n",
       " .: 246,\n",
       " Very: 247,\n",
       " sad: 248,\n",
       " about: 249,\n",
       " Iran: 250,\n",
       " .: 251,\n",
       " wompppp: 252,\n",
       " wompp: 253,\n",
       " You: 254,\n",
       " 're: 255,\n",
       " the: 256,\n",
       " only: 257,\n",
       " one: 258,\n",
       " who: 259,\n",
       " can: 260,\n",
       " see: 261,\n",
       " this: 262,\n",
       " cause: 263,\n",
       " no: 264,\n",
       " one: 265,\n",
       " else: 266,\n",
       " is: 267,\n",
       " following: 268,\n",
       " me: 269,\n",
       " this: 270,\n",
       " is: 271,\n",
       " for: 272,\n",
       " you: 273,\n",
       " because: 274,\n",
       " you: 275,\n",
       " 're: 276,\n",
       " pretty: 277,\n",
       " awesome: 278,\n",
       " &: 279,\n",
       " lt;---Sad: 280,\n",
       " level: 281,\n",
       " is: 282,\n",
       " 3: 283,\n",
       " .: 284,\n",
       " I: 285,\n",
       " was: 286,\n",
       " writing: 287,\n",
       " a: 288,\n",
       " massive: 289,\n",
       " blog: 290,\n",
       " tweet: 291,\n",
       " on: 292,\n",
       " Myspace: 293,\n",
       " and: 294,\n",
       " my: 295,\n",
       " comp: 296,\n",
       " shut: 297,\n",
       " down: 298,\n",
       " .: 299,\n",
       " Now: 300,\n",
       " it: 301,\n",
       " 's: 302,\n",
       " all: 303,\n",
       " lost: 304,\n",
       " *: 305,\n",
       " lays: 306,\n",
       " in: 307,\n",
       " fetal: 308,\n",
       " position: 309,\n",
       " *: 310,\n",
       " ...: 311,\n",
       "  : 312,\n",
       " Headed: 313,\n",
       " to: 314,\n",
       " Hospitol: 315,\n",
       " :: 316,\n",
       " Had: 317,\n",
       " to: 318,\n",
       " pull: 319,\n",
       " out: 320,\n",
       " of: 321,\n",
       " the: 322,\n",
       " Golf: 323,\n",
       " Tourny: 324,\n",
       " in: 325,\n",
       " 3rd: 326,\n",
       " place: 327,\n",
       " !: 328,\n",
       " !: 329,\n",
       " !: 330,\n",
       " !: 331,\n",
       " !: 332,\n",
       " !: 333,\n",
       " !: 334,\n",
       " !: 335,\n",
       " !: 336,\n",
       " !: 337,\n",
       " !: 338,\n",
       " I: 339,\n",
       " Think: 340,\n",
       " I: 341,\n",
       " Re: 342,\n",
       " -: 343,\n",
       " Ripped: 344,\n",
       " something: 345,\n",
       " !: 346,\n",
       " !: 347,\n",
       " !: 348,\n",
       " Yeah: 349,\n",
       " THAT: 350,\n",
       " !: 351,\n",
       " !: 352,\n",
       " BoRinG: 353,\n",
       "   : 354,\n",
       " ):: 355,\n",
       " what: 356,\n",
       " s: 357,\n",
       " wrong: 358,\n",
       " with: 359,\n",
       " him: 360,\n",
       " ?: 361,\n",
       " ?: 362,\n",
       "     : 363,\n",
       " Please: 364,\n",
       " tell: 365,\n",
       " me: 366,\n",
       " ........: 367,\n",
       "   : 368,\n",
       " :-/: 369,\n",
       " ca: 370,\n",
       " n't: 371,\n",
       " be: 372,\n",
       " bothered: 373,\n",
       " .: 374,\n",
       " i: 375,\n",
       " wish: 376,\n",
       " i: 377,\n",
       " could: 378,\n",
       " spend: 379,\n",
       " the: 380,\n",
       " rest: 381,\n",
       " of: 382,\n",
       " my: 383,\n",
       " life: 384,\n",
       " just: 385,\n",
       " sat: 386,\n",
       " here: 387,\n",
       " and: 388,\n",
       " going: 389,\n",
       " to: 390,\n",
       " gigs: 391,\n",
       " .: 392,\n",
       " seriously: 393,\n",
       " .: 394,\n",
       " Feeeling: 395,\n",
       " like: 396,\n",
       " shit: 397,\n",
       " right: 398,\n",
       " now: 399,\n",
       " .: 400,\n",
       " I: 401,\n",
       " really: 402,\n",
       " want: 403,\n",
       " to: 404,\n",
       " sleep: 405,\n",
       " ,: 406,\n",
       " but: 407,\n",
       " nooo: 408,\n",
       " I: 409,\n",
       " have: 410,\n",
       " 3: 411,\n",
       " hours: 412,\n",
       " of: 413,\n",
       " dancing: 414,\n",
       " and: 415,\n",
       " an: 416,\n",
       " art: 417,\n",
       " assignment: 418,\n",
       " to: 419,\n",
       " finish: 420,\n",
       " .: 421,\n",
       " goodbye: 422,\n",
       " exams: 423,\n",
       " ,: 424,\n",
       " HELLO: 425,\n",
       " ALCOHOL: 426,\n",
       " TONIGHT: 427,\n",
       " I: 428,\n",
       " did: 429,\n",
       " n't: 430,\n",
       " realize: 431,\n",
       " it: 432,\n",
       " was: 433,\n",
       " THAT: 434,\n",
       " deep: 435,\n",
       " .: 436,\n",
       " Geez: 437,\n",
       " give: 438,\n",
       " a: 439,\n",
       " girl: 440,\n",
       " a: 441,\n",
       " warning: 442,\n",
       " atleast: 443,\n",
       " !: 444,\n",
       " I: 445,\n",
       " hate: 446,\n",
       " it: 447,\n",
       " when: 448,\n",
       " any: 449,\n",
       " athlete: 450,\n",
       " appears: 451,\n",
       " to: 452,\n",
       " tear: 453,\n",
       " an: 454,\n",
       " ACL: 455,\n",
       " on: 456,\n",
       " live: 457,\n",
       " television: 458,\n",
       " .: 459,\n",
       " i: 460,\n",
       " miss: 461,\n",
       " you: 462,\n",
       " guys: 463,\n",
       " too: 464,\n",
       "     : 465,\n",
       " i: 466,\n",
       " think: 467,\n",
       " i: 468,\n",
       " 'm: 469,\n",
       " wearing: 470,\n",
       " skinny: 471,\n",
       " jeans: 472,\n",
       " a: 473,\n",
       " cute: 474,\n",
       " sweater: 475,\n",
       " and: 476,\n",
       " heels: 477,\n",
       "   : 478,\n",
       " not: 479,\n",
       " really: 480,\n",
       " sure: 481,\n",
       "   : 482,\n",
       " what: 483,\n",
       " are: 484,\n",
       " you: 485,\n",
       " doing: 486,\n",
       " today: 487,\n",
       " --: 488,\n",
       " Meet: 489,\n",
       " your: 490,\n",
       " Meat: 491,\n",
       " http://bit.ly/15SSCI: 492,\n",
       " My: 493,\n",
       " horsie: 494,\n",
       " is: 495,\n",
       " moving: 496,\n",
       " on: 497,\n",
       " Saturday: 498,\n",
       " morning: 499,\n",
       " .: 500,\n",
       " No: 501,\n",
       " Sat: 502,\n",
       " off: 503,\n",
       " ...: 504,\n",
       " Need: 505,\n",
       " to: 506,\n",
       " work: 507,\n",
       " 6: 508,\n",
       " days: 509,\n",
       " a: 510,\n",
       " week: 511,\n",
       " Really: 512,\n",
       " Do: 513,\n",
       " nt: 514,\n",
       " Like: 515,\n",
       " Doing: 516,\n",
       " my: 517,\n",
       " Room: 518,\n",
       " Its: 519,\n",
       " So: 520,\n",
       " Boring: 521,\n",
       "  : 522,\n",
       " Sick: 523,\n",
       " Of: 524,\n",
       " Doing: 525,\n",
       " My: 526,\n",
       " Wardrobe: 527,\n",
       " Out: 528,\n",
       " Ca: 529,\n",
       " nt: 530,\n",
       " Waiit: 531,\n",
       " Till: 532,\n",
       " I: 533,\n",
       " Have: 534,\n",
       " My: 535,\n",
       " Walk: 536,\n",
       " In: 537,\n",
       " One: 538,\n",
       "  : 539,\n",
       " Yay: 540,\n",
       " SOX: 541,\n",
       " !: 542,\n",
       "     : 543,\n",
       " Floyd: 544,\n",
       " was: 545,\n",
       " great: 546,\n",
       " ,: 547,\n",
       " but: 548,\n",
       " relievers: 549,\n",
       " need: 550,\n",
       " a: 551,\n",
       " scolding: 552,\n",
       " !: 553,\n",
       " times: 554,\n",
       " by: 555,\n",
       " like: 556,\n",
       " a: 557,\n",
       " million: 558,\n",
       " uploading: 559,\n",
       " pictures: 560,\n",
       " on: 561,\n",
       " friendster: 562,\n",
       " what: 563,\n",
       " type: 564,\n",
       " of: 565,\n",
       " a: 566,\n",
       " spaz: 567,\n",
       " downloads: 568,\n",
       " a: 569,\n",
       " virus: 570,\n",
       " ?: 571,\n",
       " my: 572,\n",
       " brother: 573,\n",
       " that: 574,\n",
       " 's: 575,\n",
       " who: 576,\n",
       " :: 577,\n",
       " \\: 578,\n",
       " MSN: 579,\n",
       " is: 580,\n",
       " now: 581,\n",
       " fucked: 582,\n",
       " forever: 583,\n",
       "    : 584,\n",
       " :'(: 585,\n",
       " &: 586,\n",
       " amp;&amp;Fightiin: 587,\n",
       " Wiit: 588,\n",
       " The: 589,\n",
       " Babes: 590,\n",
       " ...: 591,\n",
       " (:: 592,\n",
       " !: 593,\n",
       " !: 594,\n",
       " !: 595,\n",
       " !: 596,\n",
       " !: 597,\n",
       " !: 598,\n",
       " -: 599,\n",
       " so: 600,\n",
       " i: 601,\n",
       " wrote: 602,\n",
       " something: 603,\n",
       " last: 604,\n",
       " week: 605,\n",
       " .: 606,\n",
       " and: 607,\n",
       " i: 608,\n",
       " got: 609,\n",
       " a: 610,\n",
       " call: 611,\n",
       " from: 612,\n",
       " someone: 613,\n",
       " in: 614,\n",
       " the: 615,\n",
       " new: 616,\n",
       " york: 617,\n",
       " office: 618,\n",
       " ...: 619,\n",
       " http://tumblr.com/xcn21w6o7: 620,\n",
       " *: 621,\n",
       " enough: 622,\n",
       " said: 623,\n",
       " *: 624,\n",
       " ...: 625,\n",
       " Do: 626,\n",
       " I: 627,\n",
       " need: 628,\n",
       " to: 629,\n",
       " even: 630,\n",
       " say: 631,\n",
       " it: 632,\n",
       " ?: 633,\n",
       "  : 634,\n",
       " Do: 635,\n",
       " I: 636,\n",
       " ?: 637,\n",
       "  : 638,\n",
       " Well: 639,\n",
       " ,: 640,\n",
       " here: 641,\n",
       " I: 642,\n",
       " go: 643,\n",
       " anyways: 644,\n",
       " :: 645,\n",
       "  : 646,\n",
       " CHRIS: 647,\n",
       " CORNELL: 648,\n",
       " IN: 649,\n",
       " CHICAGO: 650,\n",
       " !: 651,\n",
       "  : 652,\n",
       " ...: 653,\n",
       " TONIGHT: 654,\n",
       " !: 655,\n",
       " ...: 656,\n",
       " health: 657,\n",
       " class: 658,\n",
       " (: 659,\n",
       " what: 660,\n",
       " a: 661,\n",
       " joke: 662,\n",
       " !: 663,\n",
       " ): 664,\n",
       " @ginaaa: 665,\n",
       " &: 666,\n",
       " lt;3: 667,\n",
       " GO: 668,\n",
       " TO: 669,\n",
       " THE: 670,\n",
       " SHOW: 671,\n",
       " TONIGHT: 672,\n",
       " @Spiral_galaxy: 673,\n",
       " @YMPtweet: 674,\n",
       "  : 675,\n",
       " it: 676,\n",
       " really: 677,\n",
       " makes: 678,\n",
       " me: 679,\n",
       " sad: 680,\n",
       " when: 681,\n",
       " i: 682,\n",
       " look: 683,\n",
       " at: 684,\n",
       " Muslims: 685,\n",
       " reality: 686,\n",
       " now: 687,\n",
       " -: 688,\n",
       " All: 689,\n",
       " Time: 690,\n",
       " Low: 691,\n",
       " shall: 692,\n",
       " be: 693,\n",
       " my: 694,\n",
       " motivation: 695,\n",
       " for: 696,\n",
       " the: 697,\n",
       " rest: 698,\n",
       " of: 699,\n",
       " the: 700,\n",
       " week: 701,\n",
       " .: 702,\n",
       " and: 703,\n",
       " the: 704,\n",
       " entertainment: 705,\n",
       " is: 706,\n",
       " over: 707,\n",
       " ,: 708,\n",
       " someone: 709,\n",
       " complained: 710,\n",
       " properly: 711,\n",
       " ..: 712,\n",
       "   : 713,\n",
       " @rupturerapture: 714,\n",
       " experimental: 715,\n",
       " you: 716,\n",
       " say: 717,\n",
       " ?: 718,\n",
       " he: 719,\n",
       " should: 720,\n",
       " experiment: 721,\n",
       " with: 722,\n",
       " a: 723,\n",
       " melody: 724,\n",
       " another: 725,\n",
       " year: 726,\n",
       " of: 727,\n",
       " Lakers: 728,\n",
       " ..: 729,\n",
       " That: 730,\n",
       " 's: 731,\n",
       " neither: 732,\n",
       " magic: 733,\n",
       " nor: 734,\n",
       " fun: 735,\n",
       " ...: 736,\n",
       " baddest: 737,\n",
       " day: 738,\n",
       " eveer: 739,\n",
       " .: 740,\n",
       " bathroom: 741,\n",
       " is: 742,\n",
       " clean: 743,\n",
       " .....: 744,\n",
       " now: 745,\n",
       " on: 746,\n",
       " to: 747,\n",
       " more: 748,\n",
       " enjoyable: 749,\n",
       " tasks: 750,\n",
       " ......: 751,\n",
       " boom: 752,\n",
       " boom: 753,\n",
       " pow: 754,\n",
       " but: 755,\n",
       " i: 756,\n",
       " 'm: 757,\n",
       " proud: 758,\n",
       " .: 759,\n",
       " congrats: 760,\n",
       " to: 761,\n",
       " helio: 762,\n",
       " though: 763,\n",
       " David: 764,\n",
       " must: 765,\n",
       " be: 766,\n",
       " hospitalized: 767,\n",
       " for: 768,\n",
       " five: 769,\n",
       " days: 770,\n",
       " end: 771,\n",
       " of: 772,\n",
       " July: 773,\n",
       " (: 774,\n",
       " palatine: 775,\n",
       " tonsils: 776,\n",
       " ): 777,\n",
       " .: 778,\n",
       " I: 779,\n",
       " will: 780,\n",
       " probably: 781,\n",
       " never: 782,\n",
       " see: 783,\n",
       " Katie: 784,\n",
       " in: 785,\n",
       " concert: 786,\n",
       " .: 787,\n",
       " friends: 788,\n",
       " are: 789,\n",
       " leaving: 790,\n",
       " me: 791,\n",
       " 'cause: 792,\n",
       " of: 793,\n",
       " this: 794,\n",
       " stupid: 795,\n",
       " love: 796,\n",
       "  : 797,\n",
       " http://bit.ly/ZoxZC: 798,\n",
       " go: 799,\n",
       " give: 800,\n",
       " ur: 801,\n",
       " mom: 802,\n",
       " a: 803,\n",
       " hug: 804,\n",
       " right: 805,\n",
       " now: 806,\n",
       " .: 807,\n",
       " http://bit.ly/azFwv: 808,\n",
       " Going: 809,\n",
       " To: 810,\n",
       " See: 811,\n",
       " Harry: 812,\n",
       " Sunday: 813,\n",
       " Happiness: 814,\n",
       " Hand: 815,\n",
       " quilting: 816,\n",
       " it: 817,\n",
       " is: 818,\n",
       " then: 819,\n",
       " ...: 820,\n",
       " hate: 821,\n",
       " u: 822,\n",
       " ...: 823,\n",
       "  : 824,\n",
       " leysh: 825,\n",
       " t9ar5: 826,\n",
       " ...: 827,\n",
       " =: 828,\n",
       " (: 829,\n",
       " (: 830,\n",
       " (: 831,\n",
       " (: 832,\n",
       " (: 833,\n",
       " (: 834,\n",
       " (: 835,\n",
       " ..: 836,\n",
       " -: 837,\n",
       "  : 838,\n",
       " I: 839,\n",
       " always: 840,\n",
       " get: 841,\n",
       " what: 842,\n",
       " I: 843,\n",
       " want: 844,\n",
       " I: 845,\n",
       " bend: 846,\n",
       " backwards: 847,\n",
       " i: 848,\n",
       " get: 849,\n",
       " off: 850,\n",
       " work: 851,\n",
       " sooooon: 852,\n",
       " !: 853,\n",
       " i: 854,\n",
       " miss: 855,\n",
       " cody: 856,\n",
       " booo: 857,\n",
       " .: 858,\n",
       " have: 859,\n",
       " n't: 860,\n",
       " seen: 861,\n",
       " him: 862,\n",
       " in: 863,\n",
       " foreverr: 864,\n",
       " !: 865,\n",
       " I: 866,\n",
       " hate: 867,\n",
       " allergies: 868,\n",
       " .: 869,\n",
       " Should: 870,\n",
       " I: 871,\n",
       " get: 872,\n",
       " my: 873,\n",
       " hair: 874,\n",
       " cut: 875,\n",
       " tomorrow: 876,\n",
       " ?: 877,\n",
       " I: 878,\n",
       " 'm: 879,\n",
       " taking: 880,\n",
       " a: 881,\n",
       " public: 882,\n",
       " poll: 883,\n",
       " ...: 884,\n",
       " -: 885,\n",
       " I: 886,\n",
       " love: 887,\n",
       " you: 888,\n",
       " guys: 889,\n",
       " so: 890,\n",
       " much: 891,\n",
       " that: 892,\n",
       " it: 893,\n",
       " hurts: 894,\n",
       " .: 895,\n",
       " http://tumblr.com/xkh1z19us: 896,\n",
       " I: 897,\n",
       " miss: 898,\n",
       " Earl: 899,\n",
       " I: 900,\n",
       " miss: 901,\n",
       " New: 902,\n",
       " Jersey: 903,\n",
       " I: 904,\n",
       " missed: 905,\n",
       " the: 906,\n",
       " first: 907,\n",
       " hour: 908,\n",
       " of: 909,\n",
       " SYTYCD: 910,\n",
       " last: 911,\n",
       " night: 912,\n",
       " ,: 913,\n",
       " and: 914,\n",
       " I: 915,\n",
       " ca: 916,\n",
       " n't: 917,\n",
       " find: 918,\n",
       " it: 919,\n",
       " online: 920,\n",
       " !: 921,\n",
       " I: 922,\n",
       " need: 923,\n",
       " a: 924,\n",
       " U2: 925,\n",
       " fix: 926,\n",
       " NOW: 927,\n",
       " !: 928,\n",
       " I: 929,\n",
       " never: 930,\n",
       " thought: 931,\n",
       " I: 932,\n",
       " 'd: 933,\n",
       " become: 934,\n",
       " second: 935,\n",
       " choice: 936,\n",
       " ...: 937,\n",
       " I: 938,\n",
       " think: 939,\n",
       " I: 940,\n",
       " may: 941,\n",
       " be: 942,\n",
       " too: 943,\n",
       " friendly: 944,\n",
       " ...: 945,\n",
       " lol: 946,\n",
       " ...: 947,\n",
       " o: 948,\n",
       " well: 949,\n",
       " ...: 950,\n",
       " I: 951,\n",
       " think: 952,\n",
       " Manuel: 953,\n",
       " (: 954,\n",
       " my: 955,\n",
       " Basil: 956,\n",
       " plant: 957,\n",
       " ): 958,\n",
       " only: 959,\n",
       " has: 960,\n",
       " days: 961,\n",
       " to: 962,\n",
       " live: 963,\n",
       " I: 964,\n",
       " wanna: 965,\n",
       " be: 966,\n",
       " at: 967,\n",
       " home: 968,\n",
       " @: 969,\n",
       " church: 970,\n",
       " ...: 971,\n",
       " I: 972,\n",
       " wonder: 973,\n",
       " wht: 974,\n",
       " they: 975,\n",
       " are: 976,\n",
       " doing: 977,\n",
       " ?: 978,\n",
       " i: 979,\n",
       " wanna: 980,\n",
       " make: 981,\n",
       " my: 982,\n",
       " own: 983,\n",
       " pizza: 984,\n",
       " i: 985,\n",
       " want: 986,\n",
       " a: 987,\n",
       " 120: 988,\n",
       " gb: 989,\n",
       " harddrive: 990,\n",
       " ,: 991,\n",
       " or: 992,\n",
       " a: 993,\n",
       " 37: 994,\n",
       " inch: 995,\n",
       " tv: 996,\n",
       " ,: 997,\n",
       " or: 998,\n",
       " a: 999,\n",
       " ...}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create function that indexes\n",
    "def indexer(x):\n",
    "    for w in nlp(x):\n",
    "        if w in word2index:\n",
    "            return word2index[w.lower()]\n",
    "        else: \n",
    "            return None\n",
    "    #return [word2index.get(w.lower) for w in nlp(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenize tweets and calculate lengths of each tweet\n",
    "dataset['SentimentIndex'] = dataset['SentimentText'].apply(indexer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lengths(x):\n",
    "    try:\n",
    "        len(x)\n",
    "    except:\n",
    "        return 0\n",
    "   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          None\n",
       "1          None\n",
       "2          None\n",
       "3          None\n",
       "4          None\n",
       "           ... \n",
       "1578607    None\n",
       "1578608    None\n",
       "1578609    None\n",
       "1578610    None\n",
       "1578611    None\n",
       "Name: SentimentIndex, Length: 1578612, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['SentimentIndex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "int() argument must be a string, a bytes-like object or a number, not 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-ed7052baa38e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Lengths'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SentimentIndex'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'int64'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[0;32m   5879\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5880\u001b[0m             \u001b[1;31m# else, only a single dtype is given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5881\u001b[1;33m             new_data = self._data.astype(\n\u001b[0m\u001b[0;32m   5882\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5883\u001b[0m             )\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"astype\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb_items\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malign_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mapplied\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36mastype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 559\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_astype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"raise\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\internals\\blocks.py\u001b[0m in \u001b[0;36m_astype\u001b[1;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m                     \u001b[1;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    642\u001b[0m                     \u001b[0mvals1d\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 643\u001b[1;33m                     \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvals1d\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    644\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    645\u001b[0m                 \u001b[1;31m# TODO(extension)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\pandas\\core\\dtypes\\cast.py\u001b[0m in \u001b[0;36mastype_nansafe\u001b[1;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[0;32m    705\u001b[0m         \u001b[1;31m# work around NumPy brokenness, #1987\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missubdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype_intsafe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[1;31m# if we have a datetime/timedelta array of objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.astype_intsafe\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: int() argument must be a string, a bytes-like object or a number, not 'NoneType'"
     ]
    }
   ],
   "source": [
    "dataset['Lengths'] = dataset['SentimentIndex'].astype('int64').apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = sns.distplot(dataset['Lengths'].values, kde=False)\n",
    "ax.set(xlabel='Tweet Length', ylabel = 'Freq')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'./SentimentAnalysisDataset.csv', error_bad_lines=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|███████████████████████████████| 1578612/1578612 [00:04<00:00, 346520.27it/s]\n",
      "100%|███████████████████████████████████████████| 1578612/1578612 [09:35<00:00, 2741.34it/s]\n",
      "Progress: 100%|█████████████████████████████████| 1578612/1578612 [09:06<00:00, 2890.22it/s]\n",
      "Progress: 100%|███████████████████████████████| 1578612/1578612 [00:03<00:00, 416044.80it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Text(0, 0.5, 'Frequency'), Text(0.5, 0, 'Tweet Length')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# all imports\n",
    "from collections import Counter\n",
    "import spacy\n",
    "from tqdm import tqdm, tqdm_notebook, tnrange\n",
    "tqdm.pandas(desc='Progress')\n",
    "\n",
    "# load spacy tokenizer\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'tagger', 'ner'])\n",
    "# df.progress_apply is tqdm method for pandas. It shows progress bar for apply function\n",
    "# remove the leading and trailing spaces\n",
    "df['SentimentText'] = df.SentimentText.progress_apply(lambda x: x.strip())\n",
    "\n",
    "# build vocabulary and corresponding counts\n",
    "words = Counter()\n",
    "for sent in tqdm(df.SentimentText.values):\n",
    "    words.update(w.text.lower() for w in nlp(sent))\n",
    "   \n",
    "# sort with most frequently occuring words first\n",
    "words = sorted(words, key=words.get, reverse=True)\n",
    "# add <pad> and <unk> token to vocab which will be used later\n",
    "words = ['_PAD','_UNK'] + words\n",
    "\n",
    "# create word to index dictionary and reverse\n",
    "word2idx = {o:i for i,o in enumerate(words)}\n",
    "idx2word = {i:o for i,o in enumerate(words)}\n",
    "\n",
    "def indexer(s): \n",
    "  return [word2idx[w.text.lower()] for w in nlp(s)]\n",
    "\n",
    "# tokenize the tweets and calculate lengths\n",
    "df['sentimentidx'] = df.SentimentText.progress_apply(indexer)\n",
    "df['lengths'] = df.sentimentidx.progress_apply(len)\n",
    "\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "ax = sns.distplot(df.lengths.values,kde=False);\n",
    "ax.set(xlabel='Tweet Length', ylabel='Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ItemID</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentSource</th>\n",
       "      <th>SentimentText</th>\n",
       "      <th>sentimentidx</th>\n",
       "      <th>lengths</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>is so sad for my APL friend.............</td>\n",
       "      <td>[14, 26, 132, 18, 10, 241470, 266, 6618]</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>I missed the New Moon trailer...</td>\n",
       "      <td>[2, 272, 7, 91, 812, 1274, 16]</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>omg its already 7:30 :O</td>\n",
       "      <td>[247, 82, 217, 4572, 1012]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>.. Omgaga. Im sooo  im gunna CRy. I've been at...</td>\n",
       "      <td>[37, 241471, 4, 2, 73, 440, 6, 2, 73, 1453, 55...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Sentiment140</td>\n",
       "      <td>i think mi bf is cheating on me!!!       T_T</td>\n",
       "      <td>[2, 93, 1813, 1342, 14, 5541, 23, 24, 3, 3, 3,...</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ItemID  Sentiment SentimentSource  \\\n",
       "0       1          0    Sentiment140   \n",
       "1       2          0    Sentiment140   \n",
       "2       3          1    Sentiment140   \n",
       "3       4          0    Sentiment140   \n",
       "4       5          0    Sentiment140   \n",
       "\n",
       "                                       SentimentText  \\\n",
       "0           is so sad for my APL friend.............   \n",
       "1                   I missed the New Moon trailer...   \n",
       "2                            omg its already 7:30 :O   \n",
       "3  .. Omgaga. Im sooo  im gunna CRy. I've been at...   \n",
       "4       i think mi bf is cheating on me!!!       T_T   \n",
       "\n",
       "                                        sentimentidx  lengths  \n",
       "0           [14, 26, 132, 18, 10, 241470, 266, 6618]        8  \n",
       "1                     [2, 272, 7, 91, 812, 1274, 16]        7  \n",
       "2                         [247, 82, 217, 4572, 1012]        5  \n",
       "3  [37, 241471, 4, 2, 73, 440, 6, 2, 73, 1453, 55...       35  \n",
       "4  [2, 93, 1813, 1342, 14, 5541, 23, 24, 3, 3, 3,...       13  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create pytorch dataset and dataloader\n",
    "\n",
    "# subclass the custom dataset class with torch.utils.data.Dataset\n",
    "# implement __len__ and __getitem__ function\n",
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df_path):\n",
    "        self.df = pd.read_csv(df_path, error_bad_lines=False)\n",
    "        self.df['SentimentText'] = self.df.SentimentText.apply(lambda x: x.strip())\n",
    "        self.df['sentimentidx'] = self.df.SentimentText.apply(indexer)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.df.sentimentidx[idx]\n",
    "        y = self.df.Sentiment[idx]\n",
    "        return x,y\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0             [14, 26, 132, 18, 10, 241470, 266, 6618]\n",
      "1                       [2, 272, 7, 91, 812, 1274, 16]\n",
      "2                           [247, 82, 217, 4572, 1012]\n",
      "3    [37, 241471, 4, 2, 73, 440, 6, 2, 73, 1453, 55...\n",
      "Name: sentimentidx, dtype: object, 0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "Name: Sentiment, dtype: int64)\n"
     ]
    }
   ],
   "source": [
    "# create instance of custom dataset\n",
    "ds = VectorizeData('./SentimentAnalysisDataset.csv')\n",
    "# get first 4 samples\n",
    "print(ds[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Samples  526204\n",
      "Length of smallest tweet 5\n",
      "<class 'list'>\n",
      "[tensor([ 14,   2, 247]), tensor([ 26, 272,  82]), tensor([132,   7, 217]), tensor([  18,   91, 4572]), tensor([  10,  812, 1012])]\n"
     ]
    }
   ],
   "source": [
    "#We'll use the pytorch Dataload so we can use the custom data set above\n",
    "\n",
    "\n",
    "dl = DataLoader(dataset=ds, batch_size=3)\n",
    "print('Total Samples ', len(dl))\n",
    "\n",
    "it = iter(dl)\n",
    "xs, ys = next(it)\n",
    "print('Length of smallest tweet', len(xs))\n",
    "print(type(xs))\n",
    "print(xs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 8836: expected 4 fields, saw 5\\n'\n",
      "b'Skipping line 535882: expected 4 fields, saw 7\\n'\n",
      "Progress:   0%|                                     | 493/1578612 [00:00<05:22, 4890.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|█████████████████████████████████| 1578612/1578612 [09:40<00:00, 2718.29it/s]\n",
      "Progress:   1%|▏                                  | 9693/1578612 [00:00<00:16, 96235.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating lengths\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|███████████████████████████████| 1578612/1578612 [00:04<00:00, 352172.03it/s]\n",
      "Progress:   0%|                                   | 1679/1578612 [00:00<01:34, 16734.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|███████████████████████████████| 1578612/1578612 [00:14<00:00, 109953.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0    [14, 26, 132, 18, 10, 241470, 266, 6618, 0, 0]\n",
      "1           [2, 272, 7, 91, 812, 1274, 16, 0, 0, 0]\n",
      "2         [247, 82, 217, 4572, 1012, 0, 0, 0, 0, 0]\n",
      "3       [37, 241471, 4, 2, 73, 440, 6, 2, 73, 1453]\n",
      "4       [2, 93, 1813, 1342, 14, 5541, 23, 24, 3, 3]\n",
      "Name: sentimentpadded, dtype: object, 0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: Sentiment, dtype: int64, 0     8\n",
      "1     7\n",
      "2     5\n",
      "3    10\n",
      "4    10\n",
      "Name: lengths, dtype: int64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Pad the data set and calculate lengths of tweets\n",
    "#any tweet shorter than 10 is padded with zeros \n",
    "class VectorizeData(Dataset):\n",
    "    def __init__(self, df_path, maxlen=10):\n",
    "        self.maxlen = maxlen\n",
    "        self.df = pd.read_csv(df_path, error_bad_lines=False)\n",
    "        self.df['SentimentText'] = self.df.SentimentText.apply(lambda x: x.strip())\n",
    "        print('Indexing...')\n",
    "        self.df['sentimentidx'] = self.df.SentimentText.progress_apply(indexer)\n",
    "        print('Calculating lengths')\n",
    "        self.df['lengths'] = self.df.sentimentidx.progress_apply(lambda x: self.maxlen if len(x) > self.maxlen else len(x))\n",
    "        print('Padding')\n",
    "        self.df['sentimentpadded'] = self.df.sentimentidx.progress_apply(self.pad_data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.df.sentimentpadded[idx]\n",
    "        lens = self.df.lengths[idx]\n",
    "        y = self.df.Sentiment[idx]\n",
    "        return X,y,lens\n",
    "    \n",
    "    def pad_data(self, s):\n",
    "        padded = np.zeros((self.maxlen,), dtype=np.int64)\n",
    "        if len(s) > self.maxlen: padded[:] = s[:self.maxlen]\n",
    "        else: padded[:len(s)] = s\n",
    "        return padded\n",
    "     \n",
    "ds = VectorizeData('./SentimentAnalysisDataset.csv')\n",
    "print(ds[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "526204\n",
      "<class 'torch.Tensor'>\n",
      "tensor([[    14,     26,    132,     18,     10, 241470,    266,   6618,      0,\n",
      "              0],\n",
      "        [     2,    272,      7,     91,    812,   1274,     16,      0,      0,\n",
      "              0],\n",
      "        [   247,     82,    217,   4572,   1012,      0,      0,      0,      0,\n",
      "              0]])\n"
     ]
    }
   ],
   "source": [
    "dl = DataLoader(dataset=ds, batch_size=3)\n",
    "print(len(dl))\n",
    "# 526204\n",
    "\n",
    "it = iter(dl)\n",
    "xs,ys,lens =  next(it)\n",
    "print(type(xs))\n",
    "print(xs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(words)\n",
    "embedding_dim = 4\n",
    "n_hidden = 5\n",
    "n_out = 2\n",
    "\n",
    "\n",
    "class SimpleGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.embedding_dim,self.n_hidden,self.n_out = vocab_size, embedding_dim, n_hidden, n_out\n",
    "        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden)\n",
    "        self.out = nn.Linear(self.n_hidden, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        bs = seq.size(1) # batch size\n",
    "        print('batch size', bs)\n",
    "        self.h = self.init_hidden(bs) # initialize hidden state of GRU\n",
    "        print('Inititial hidden state shape', self.h.shape)\n",
    "        embs = self.emb(seq)\n",
    "        embs = pack_padded_sequence(embs, lengths, enforce_sorted=False) # unpad\n",
    "        gru_out, self.h = self.gru(embs, self.h) # gru returns hidden state of all timesteps as well as hidden state at last timestep\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out) # pad the sequence to the max length in the batch\n",
    "        print('GRU output(all timesteps)', gru_out.shape)\n",
    "        print(gru_out)\n",
    "        print('GRU last timestep output')\n",
    "        print(gru_out[-1])\n",
    "        print('Last hidden state', self.h)\n",
    "        # since it is as classification problem, we will grab the last hidden state\n",
    "        outp = self.out(self.h[-1]) # self.h[-1] contains hidden state of last timestep\n",
    "        return F.log_softmax(outp, dim=-1)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros((1,batch_size,self.n_hidden)))\n",
    "      \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleGRU(\n",
      "  (emb): Embedding(771641, 4)\n",
      "  (gru): GRU(4, 5)\n",
      "  (out): Linear(in_features=5, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "m = SimpleGRU(vocab_size, embedding_dim, n_hidden, n_out)\n",
    "print(m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size 10\n",
      "Inititial hidden state shape torch.Size([1, 10, 5])\n",
      "GRU output(all timesteps) torch.Size([10, 10, 5])\n",
      "tensor([[[ 1.5927e-01, -4.6619e-01,  1.9066e-01,  4.1994e-03,  3.7057e-02],\n",
      "         [ 1.5863e-01, -2.1085e-01,  1.6785e-01,  5.9634e-02, -1.6279e-02],\n",
      "         [ 1.8155e-01, -4.6506e-01,  2.8732e-01,  1.5913e-01,  2.8127e-01],\n",
      "         [-1.1618e-01, -5.8553e-02, -7.2759e-02, -1.2994e-01, -2.4673e-01],\n",
      "         [ 1.8920e-01, -2.8359e-01, -1.4031e-01, -1.3803e-01, -1.8564e-01],\n",
      "         [ 1.2858e-01,  5.5468e-02, -2.0023e-01, -2.1786e-01, -2.8330e-01],\n",
      "         [ 1.5863e-01, -2.1085e-01,  1.6785e-01,  5.9634e-02, -1.6279e-02],\n",
      "         [-1.3427e-01, -2.3457e-01, -2.0010e-02, -5.4048e-02, -1.4306e-02],\n",
      "         [ 3.1351e-01, -1.9472e-01, -2.5952e-01, -1.6758e-01, -3.3856e-01],\n",
      "         [ 7.9451e-02,  1.1031e-01,  5.9404e-02,  1.6635e-01, -1.3874e-01]],\n",
      "\n",
      "        [[ 5.3928e-03,  3.7701e-02,  2.2319e-01,  9.1503e-02, -4.0688e-03],\n",
      "         [ 3.2127e-01,  2.9060e-01,  6.2449e-02, -1.6428e-02, -2.3004e-01],\n",
      "         [ 3.1792e-01, -7.2656e-01,  4.3766e-01,  1.8495e-01,  4.1566e-01],\n",
      "         [ 5.0534e-02, -4.2378e-01,  1.6334e-01, -1.1146e-01, -1.8004e-01],\n",
      "         [ 3.6364e-01, -3.8075e-01, -1.5941e-01, -2.1707e-01, -2.6787e-01],\n",
      "         [ 3.1860e-01, -4.3009e-01, -1.4899e-01, -2.7501e-01, -1.8203e-01],\n",
      "         [ 3.0335e-01,  1.0347e-01,  2.3523e-01,  1.9413e-01, -2.8443e-01],\n",
      "         [ 3.9158e-02, -2.9116e-01,  1.8254e-01,  1.6814e-02, -2.3552e-02],\n",
      "         [-2.9867e-02, -3.8676e-01,  1.4957e-02,  6.6433e-02, -3.6523e-02],\n",
      "         [ 1.9511e-01, -2.4875e-01,  2.8987e-01,  3.1009e-01,  7.7568e-02]],\n",
      "\n",
      "        [[-2.1613e-02, -1.7389e-01,  5.9286e-02, -5.2271e-02, -1.0932e-01],\n",
      "         [ 2.9792e-01, -2.4165e-01,  6.6923e-02, -4.2352e-02, -1.0943e-01],\n",
      "         [ 2.6479e-01, -4.2855e-01,  2.9505e-01,  8.4367e-02,  2.6093e-01],\n",
      "         [ 2.2556e-01, -5.8936e-01,  2.5668e-01,  4.0272e-03,  3.4391e-02],\n",
      "         [ 4.2586e-01, -3.0011e-01,  1.8888e-01, -1.2726e-01, -2.2420e-01],\n",
      "         [ 5.2087e-01, -5.9306e-01, -1.2784e-01, -3.3426e-01, -3.3612e-01],\n",
      "         [-1.3244e-02, -2.3217e-01,  2.5930e-01,  2.5254e-01,  1.4549e-01],\n",
      "         [-1.5185e-01, -5.3344e-02,  4.8843e-02, -1.8590e-01, -1.8986e-01],\n",
      "         [-1.5811e-01,  2.6021e-01,  1.2523e-02,  5.0128e-02, -2.1273e-01],\n",
      "         [ 2.3250e-01, -3.3529e-01,  5.2077e-02,  2.8825e-02, -2.1389e-01]],\n",
      "\n",
      "        [[ 1.3433e-01, -2.5463e-01,  2.2668e-01,  1.8284e-02, -9.4886e-02],\n",
      "         [ 4.6730e-01, -6.1582e-02,  1.2166e-01, -7.1039e-02, -2.6727e-01],\n",
      "         [ 3.3060e-01, -6.1184e-01,  8.4276e-02, -1.0606e-02,  1.4757e-01],\n",
      "         [-1.0868e-02, -6.7432e-01,  2.7121e-01,  1.2811e-01,  3.5471e-01],\n",
      "         [-8.7965e-02, -4.3858e-01,  1.4078e-01, -1.2675e-01,  1.1671e-01],\n",
      "         [ 6.6136e-01, -6.9761e-01,  1.8065e-01, -3.3857e-01, -3.4025e-01],\n",
      "         [-1.5187e-01, -5.0793e-01,  3.3018e-01,  3.2630e-01,  3.5791e-01],\n",
      "         [ 2.9532e-02, -3.7128e-01, -2.1377e-03, -2.0062e-01, -1.8596e-01],\n",
      "         [-2.3259e-01, -3.1511e-01, -1.7456e-01, -1.1715e-01, -6.8850e-02],\n",
      "         [ 2.4769e-01, -3.4211e-01, -8.2898e-02, -1.6381e-01, -3.5990e-01]],\n",
      "\n",
      "        [[ 2.9534e-01,  3.8617e-01,  4.0715e-03, -8.7672e-02, -2.4407e-01],\n",
      "         [ 4.4881e-01,  1.0004e-01, -7.4708e-02, -2.4804e-01, -4.6861e-01],\n",
      "         [ 3.5863e-01, -2.5050e-01, -6.6111e-02, -2.2089e-01, -3.0674e-01],\n",
      "         [ 2.7362e-01, -5.0014e-01, -5.3641e-02,  1.3787e-02,  2.9335e-02],\n",
      "         [-1.6114e-01, -6.4571e-01, -1.6942e-01, -3.1392e-01, -3.5862e-02],\n",
      "         [ 6.7112e-01, -6.9317e-01,  3.1427e-01, -1.7362e-01, -5.1640e-02],\n",
      "         [-3.4809e-02, -5.7172e-01,  2.9763e-01,  3.1107e-01,  2.5189e-01],\n",
      "         [ 6.9978e-02, -3.3260e-01,  8.1519e-02, -7.9958e-03, -1.1667e-01],\n",
      "         [-2.0239e-02, -1.6609e-01,  5.4350e-02, -1.1003e-01, -1.3134e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 7.4706e-02, -4.3138e-02, -4.2238e-02, -1.5764e-01, -2.2952e-01],\n",
      "         [ 5.2908e-01,  2.3922e-02, -1.2187e-01, -3.1722e-01, -5.2976e-01],\n",
      "         [ 4.6117e-01, -2.2460e-01,  4.3933e-02, -1.8539e-01, -3.6028e-01],\n",
      "         [ 1.3639e-01, -3.8424e-01, -7.1405e-02, -1.3008e-01, -9.8492e-02],\n",
      "         [-3.4765e-01, -4.2927e-01, -2.7589e-01, -4.8628e-01, -1.8617e-01],\n",
      "         [ 6.4448e-01,  1.7153e-01,  2.1705e-01, -2.2226e-01, -2.7724e-01],\n",
      "         [-1.1556e-01, -4.2381e-02,  3.5264e-01,  4.2609e-01,  2.5174e-01],\n",
      "         [-2.2941e-01, -3.2556e-01,  7.0666e-02, -4.8927e-02, -3.8920e-02],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 2.5867e-01, -1.7109e-01,  1.7693e-02, -1.2856e-01, -3.0634e-01],\n",
      "         [ 4.2536e-01, -3.9730e-01,  3.3537e-02, -3.2992e-01, -2.5955e-01],\n",
      "         [ 5.2313e-01, -5.0046e-01,  4.4967e-02, -1.9172e-01, -1.5400e-01],\n",
      "         [ 2.4747e-01, -3.2227e-01,  1.9331e-01, -5.3315e-02, -9.2566e-02],\n",
      "         [-1.0703e-01, -6.0398e-01,  1.0617e-01, -2.0080e-01,  1.9407e-02],\n",
      "         [ 6.7510e-01,  5.7081e-01,  4.1279e-04, -3.0097e-01, -4.1938e-01],\n",
      "         [ 1.1865e-01, -5.1073e-01, -5.8138e-02,  2.3811e-01,  9.4592e-02],\n",
      "         [ 1.9484e-03, -1.4462e-01,  2.4314e-01, -1.2710e-02, -1.1380e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 3.5445e-01, -2.2008e-01,  2.4430e-01, -4.8858e-02, -2.4658e-01],\n",
      "         [ 3.3417e-01, -4.0619e-01,  1.3406e-02, -3.7742e-01, -2.9682e-01],\n",
      "         [ 5.5351e-01, -8.0714e-02,  2.3065e-01, -1.5074e-01, -2.1311e-01],\n",
      "         [-8.9667e-02, -2.3745e-01,  5.4500e-02, -2.6379e-01, -2.2244e-01],\n",
      "         [-3.3861e-04, -3.3506e-01,  3.6238e-01,  7.2446e-03,  6.6763e-02],\n",
      "         [ 7.0502e-01,  6.3410e-01,  1.6794e-01, -1.4614e-01, -4.6529e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 4.6302e-01,  4.1161e-01,  4.9338e-02, -1.3742e-01, -3.6830e-01],\n",
      "         [ 3.2844e-01, -3.5668e-01, -6.8397e-02, -4.2628e-01, -4.0415e-01],\n",
      "         [ 3.6761e-01, -4.2826e-01,  3.4582e-01, -4.3861e-02,  9.5803e-02],\n",
      "         [ 9.4426e-02, -3.7501e-01,  2.8680e-01, -2.2160e-01, -1.9936e-01],\n",
      "         [ 2.0667e-01,  3.1085e-01,  1.3196e-01, -5.6131e-02, -3.9129e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "        [[ 6.2621e-01, -1.8528e-01,  5.4340e-02, -1.4540e-01, -3.9988e-01],\n",
      "         [ 3.2375e-01, -3.2799e-01, -1.0276e-01, -4.5869e-01, -4.6375e-01],\n",
      "         [ 2.2629e-01, -4.5820e-01,  3.7569e-01,  4.7718e-02,  1.5158e-01],\n",
      "         [-4.2826e-02,  2.6445e-01,  2.4952e-01, -1.7787e-02, -3.1802e-01],\n",
      "         [ 2.9035e-01,  2.6482e-01,  2.9191e-01,  5.0303e-02, -3.5449e-01],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]]],\n",
      "       grad_fn=<IndexSelectBackward>)\n",
      "GRU last timestep output\n",
      "tensor([[ 0.6262, -0.1853,  0.0543, -0.1454, -0.3999],\n",
      "        [ 0.3237, -0.3280, -0.1028, -0.4587, -0.4638],\n",
      "        [ 0.2263, -0.4582,  0.3757,  0.0477,  0.1516],\n",
      "        [-0.0428,  0.2644,  0.2495, -0.0178, -0.3180],\n",
      "        [ 0.2904,  0.2648,  0.2919,  0.0503, -0.3545],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<SelectBackward>)\n",
      "Last hidden state tensor([[[ 0.6262, -0.1853,  0.0543, -0.1454, -0.3999],\n",
      "         [ 0.3237, -0.3280, -0.1028, -0.4587, -0.4638],\n",
      "         [ 0.2263, -0.4582,  0.3757,  0.0477,  0.1516],\n",
      "         [-0.0428,  0.2644,  0.2495, -0.0178, -0.3180],\n",
      "         [ 0.2904,  0.2648,  0.2919,  0.0503, -0.3545],\n",
      "         [ 0.7050,  0.6341,  0.1679, -0.1461, -0.4653],\n",
      "         [ 0.1187, -0.5107, -0.0581,  0.2381,  0.0946],\n",
      "         [ 0.0019, -0.1446,  0.2431, -0.0127, -0.1138],\n",
      "         [-0.0202, -0.1661,  0.0544, -0.1100, -0.1313],\n",
      "         [ 0.2477, -0.3421, -0.0829, -0.1638, -0.3599]]],\n",
      "       grad_fn=<IndexSelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# function to sort batch according to tweet length\n",
    "def sort_batch(X, y, lengths):\n",
    "    lengths, indx = lengths.sort(dim=0, descending=True)\n",
    "    X = X[indx]\n",
    "    y = y[indx]\n",
    "    return X.transpose(0,1), y, lengths # transpose (batch x seq_length) to (seq_length x batch)\n",
    "  \n",
    "\n",
    "dl = DataLoader(ds, batch_size=10)\n",
    "it = iter(dl)\n",
    "xs,ys,lens =  next(it)\n",
    "xs,ys,lens = sort_batch(xs,ys,lens)\n",
    "outp = m(xs,lens.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define training loops\n",
    "\n",
    "def process_function(engine, batch):\n",
    "    \"\"\"Single training loop to be attached to trainer Engine\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x, y, lens = batch\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    y_pred = model(x, lens)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item(), torch.max(y_pred, dim=1)[1], y\n",
    "\n",
    "\n",
    "def eval_function(engine, batch):\n",
    "    \"\"\"Single evaluator loop to be attached to trainer and evaluator Engine\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x, y, lens = batch\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        y_pred = model(x, lens)\n",
    "        return y_pred, y\n",
    "    \n",
    "trainer = Engine(process_function)\n",
    "train_evaluator = Engine(eval_function)\n",
    "validation_evaluator = Engine(eval_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConcatPoolingGRUAdaptive(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, n_hidden, n_out):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_out = n_out\n",
    "        self.emb = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
    "        self.emb_drop = nn.Dropout(0.3)\n",
    "        self.gru = nn.GRU(self.embedding_dim, self.n_hidden, dropout=0.3)\n",
    "        self.out = nn.Linear(self.n_hidden*3, self.n_out)\n",
    "        \n",
    "    def forward(self, seq, lengths):\n",
    "        self.h = self.init_hidden(seq.size(1))\n",
    "        embs = self.emb_drop(self.emb(seq))\n",
    "        embs = pack_padded_sequence(embs, lengths, enforce_sorted=False)\n",
    "        gru_out, self.h = self.gru(embs, self.h)\n",
    "        gru_out, lengths = pad_packed_sequence(gru_out)        \n",
    "        \n",
    "        avg_pool = F.adaptive_avg_pool1d(gru_out.permute(1,2,0),1).view(seq.size(1),-1)\n",
    "        max_pool = F.adaptive_max_pool1d(gru_out.permute(1,2,0),1).view(seq.size(1),-1)\n",
    "\n",
    "        outp = self.out(torch.cat([self.h[-1],avg_pool,max_pool],dim=1))             \n",
    "        return F.log_softmax(outp, dim=-1) # it will return log of softmax\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return torch.zeros((1, batch_size,self.n_hidden), requires_grad=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_vocab_size = vocab_size + 2\n",
    "embedding_dim = 100\n",
    "rnn_hidden = 256\n",
    "n_out = 2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#model = SimpleGRU(vocab_size, embedding_dim, n_hidden, n_out)\n",
    "model = ConcatPoolingGRUAdaptive(model_vocab_size, embedding_dim, rnn_hidden, n_out).to(device) \n",
    "optimizer = optim.Adam(model.parameters(), 1e-3)\n",
    "loss_fn = F.nll_loss\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def max_output_transform(output):\n",
    "    \"\"\"It convers the predicted ouput probabilties to indexes for accuracy calculation\n",
    "    \"\"\"\n",
    "    y_pred, y = output\n",
    "    return torch.max(y_pred, dim=1)[1], y\n",
    "\n",
    "# attach running loss (will be displayed in progess bar)\n",
    "RunningAverage(output_transform=lambda x: x[0]).attach(trainer, 'loss')\n",
    "\n",
    "# attach running accuracy (will be displayed in progess bar)\n",
    "RunningAverage(Accuracy(output_transform=lambda x: [x[1], x[2]])).attach(trainer, 'acc')\n",
    "\n",
    "# attach accuracy and loss to train_evaluator\n",
    "Accuracy(output_transform=max_output_transform).attach(train_evaluator, 'accuracy')\n",
    "Loss(loss_fn).attach(train_evaluator, 'bce')\n",
    "\n",
    "# attach accuracy and loss to validation_evaluator\n",
    "Accuracy(output_transform=max_output_transform).attach(validation_evaluator, 'accuracy')\n",
    "Loss(loss_fn).attach(validation_evaluator, 'bce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbar = ProgressBar(persist=True, bar_format=\"\")\n",
    "pbar.attach(trainer, ['loss', 'acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_training_results(engine):\n",
    "    \"\"\"This function will run after each epoch and \n",
    "       report the training loss and accuracy (defined above)\n",
    "    \"\"\"\n",
    "    train_evaluator.run(train_dl)\n",
    "    metrics = train_evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_bce = metrics['bce']\n",
    "    pbar.log_message(\n",
    "        f'Training Results - Epoch: {engine.state.epoch}  Avg accuracy: {avg_accuracy:.4f} Avg loss: {avg_bce:.4f}')\n",
    "    \n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(engine):\n",
    "    \"\"\"This function will run after each epoch and \n",
    "       report the validation loss and accuracy (defined above)\n",
    "    \"\"\"\n",
    "    validation_evaluator.run(val_dl)\n",
    "    metrics = validation_evaluator.state.metrics\n",
    "    avg_accuracy = metrics['accuracy']\n",
    "    avg_bce = metrics['bce']\n",
    "    pbar.log_message(\n",
    "        f'Validation Results - Epoch: {engine.state.epoch}  Avg accuracy: {avg_accuracy:.4f} Avg loss: {avg_bce:.4f}')\n",
    "    pbar.n = pbar.last_print_n = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ignite.engine.events.RemovableEventHandle at 0x299bc3359d0>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def score_function(engine):\n",
    "    \"\"\"EarlyStopping will call this function to check if score improved\n",
    "    \"\"\"\n",
    "    val_loss = engine.state.metrics['bce']\n",
    "    return -val_loss\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(patience=3, score_function=score_function, trainer=trainer)\n",
    "validation_evaluator.add_event_handler(Events.COMPLETED, early_stopping)\n",
    "\n",
    "checkpointer = ModelCheckpoint(\n",
    "    './models', \n",
    "    'text_gru_concat', \n",
    "    save_interval=1, \n",
    "    n_saved=1, \n",
    "    create_dir=True, \n",
    "    save_as_state_dict=True)\n",
    "\n",
    "trainer.add_event_handler(Events.EPOCH_COMPLETED, checkpointer, {'sentiment': model})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a75c8840d784132a12833393eb3d4c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=157862.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Engine run is terminating due to exception: .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-139-ed5119e9783a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[0;32m    656\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 658\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    659\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    660\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    724\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[1;34m(self, e)\u001b[0m\n\u001b[0;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 437\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    695\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 697\u001b[1;33m                 \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    698\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m                 \u001b[0mhours\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_to_hours_mins_secs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtime_taken\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ignite\\engine\\engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    769\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 771\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    772\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    773\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-111-c1f8c68929c7>\u001b[0m in \u001b[0;36mprocess_function\u001b[1;34m(engine, batch)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\kwaz9\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m     98\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m                     \u001b[1;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.run(dl, max_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
